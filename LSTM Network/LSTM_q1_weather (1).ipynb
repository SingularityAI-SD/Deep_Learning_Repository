{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install watermark"
      ],
      "metadata": {
        "id": "mNrTmrR0m4Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext watermark"
      ],
      "metadata": {
        "id": "JkysPFJum4La"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%watermark -a \"Rishit Kapoor 21BAI1046\" -u -d -v -m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOOvMycFm4A-",
        "outputId": "711ccef0-aa3e-4673-ab37-de3a530a1ab8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Rishit Kapoor 21BAI1046\n",
            "\n",
            "Last updated: 2024-04-13\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.58+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "ucyDY2d6m3-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "rxByfxvkm38C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "pmmEBVYGm333"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QwF0eX8Xm31D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download muthuj7/weather-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vlx7n2UnFfR",
        "outputId": "a1411592-aa6f-4f27-927a-da04c68652a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading weather-dataset.zip to /content\n",
            " 90% 2.00M/2.23M [00:01<00:00, 2.20MB/s]\n",
            "100% 2.23M/2.23M [00:01<00:00, 2.10MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/weather-dataset.zip' -d '/content/weather-dataset'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Ux1bqonFNj",
        "outputId": "fc528980-f129-4e23-f4df-aadb4c5e184c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/weather-dataset.zip\n",
            "  inflating: /content/weather-dataset/weatherHistory.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import math\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Define the modified split_sequence function\n",
        "def split_sequence(sequence, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the sequence\n",
        "        if end_ix > len(sequence)-1:\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"/content/weather-dataset/weatherHistory.csv\")\n",
        "\n",
        "# Select only the 'Temperature (C)' column\n",
        "temperature_data = data['Temperature (C)'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(temperature_data)\n",
        "\n",
        "# Define the number of time steps\n",
        "n_steps = 10\n",
        "\n",
        "# Split the temperature sequence into input/output\n",
        "X, y = split_sequence(scaled_data, n_steps)\n",
        "\n",
        "# Reshape data for LSTM [samples, time steps, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(n_steps, 1)))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, batch_size=32)\n",
        "\n",
        "# Predict on the last time step of the data\n",
        "last_sequence = scaled_data[-n_steps:]\n",
        "last_sequence = last_sequence.reshape((1, n_steps, 1))\n",
        "predicted_temperature = model.predict(last_sequence)\n",
        "\n",
        "# Inverse transform the predicted temperature\n",
        "predicted_temperature = scaler.inverse_transform(predicted_temperature)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_urauQCSrWxE",
        "outputId": "aef883ea-282b-4924-8016-3ad3e3d58005"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3014/3014 [==============================] - 23s 6ms/step - loss: 0.0023\n",
            "Epoch 2/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 5.8827e-04\n",
            "Epoch 3/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 5.5905e-04\n",
            "Epoch 4/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 5.4896e-04\n",
            "Epoch 5/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 5.3825e-04\n",
            "Epoch 6/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 5.3293e-04\n",
            "Epoch 7/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 5.2974e-04\n",
            "Epoch 8/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 5.2452e-04\n",
            "Epoch 9/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 5.1995e-04\n",
            "Epoch 10/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 5.1514e-04\n",
            "Epoch 11/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 5.1079e-04\n",
            "Epoch 12/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 5.0716e-04\n",
            "Epoch 13/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.9996e-04\n",
            "Epoch 14/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.9599e-04\n",
            "Epoch 15/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.9024e-04\n",
            "Epoch 16/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.8349e-04\n",
            "Epoch 17/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.8369e-04\n",
            "Epoch 18/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.7959e-04\n",
            "Epoch 19/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.7728e-04\n",
            "Epoch 20/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.7476e-04\n",
            "Epoch 21/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.7172e-04\n",
            "Epoch 22/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.7012e-04\n",
            "Epoch 23/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.6563e-04\n",
            "Epoch 24/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.6499e-04\n",
            "Epoch 25/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.6258e-04\n",
            "Epoch 26/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.5863e-04\n",
            "Epoch 27/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.5772e-04\n",
            "Epoch 28/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.5676e-04\n",
            "Epoch 29/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.5355e-04\n",
            "Epoch 30/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.5240e-04\n",
            "Epoch 31/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.5249e-04\n",
            "Epoch 32/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.5087e-04\n",
            "Epoch 33/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.4877e-04\n",
            "Epoch 34/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.4816e-04\n",
            "Epoch 35/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.4674e-04\n",
            "Epoch 36/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.4689e-04\n",
            "Epoch 37/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.4514e-04\n",
            "Epoch 38/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.4550e-04\n",
            "Epoch 39/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.4395e-04\n",
            "Epoch 40/100\n",
            "3014/3014 [==============================] - 22s 7ms/step - loss: 4.4403e-04\n",
            "Epoch 41/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.4229e-04\n",
            "Epoch 42/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.4201e-04\n",
            "Epoch 43/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.4050e-04\n",
            "Epoch 44/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.4061e-04\n",
            "Epoch 45/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.4079e-04\n",
            "Epoch 46/100\n",
            "3014/3014 [==============================] - 20s 7ms/step - loss: 4.3914e-04\n",
            "Epoch 47/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.3780e-04\n",
            "Epoch 48/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.3769e-04\n",
            "Epoch 49/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.3765e-04\n",
            "Epoch 50/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.3635e-04\n",
            "Epoch 51/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.3644e-04\n",
            "Epoch 52/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.3470e-04\n",
            "Epoch 53/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.3513e-04\n",
            "Epoch 54/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.3362e-04\n",
            "Epoch 55/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.3305e-04\n",
            "Epoch 56/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.3353e-04\n",
            "Epoch 57/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.3315e-04\n",
            "Epoch 58/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.3110e-04\n",
            "Epoch 59/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.3094e-04\n",
            "Epoch 60/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2852e-04\n",
            "Epoch 61/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2872e-04\n",
            "Epoch 62/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2804e-04\n",
            "Epoch 63/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2898e-04\n",
            "Epoch 64/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2852e-04\n",
            "Epoch 65/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2778e-04\n",
            "Epoch 66/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.2767e-04\n",
            "Epoch 67/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2610e-04\n",
            "Epoch 68/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.2696e-04\n",
            "Epoch 69/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2452e-04\n",
            "Epoch 70/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.2519e-04\n",
            "Epoch 71/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2352e-04\n",
            "Epoch 72/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.2424e-04\n",
            "Epoch 73/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2299e-04\n",
            "Epoch 74/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.2244e-04\n",
            "Epoch 75/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2320e-04\n",
            "Epoch 76/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.2209e-04\n",
            "Epoch 77/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2140e-04\n",
            "Epoch 78/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.2197e-04\n",
            "Epoch 79/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2032e-04\n",
            "Epoch 80/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2111e-04\n",
            "Epoch 81/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.2005e-04\n",
            "Epoch 82/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2022e-04\n",
            "Epoch 83/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.1971e-04\n",
            "Epoch 84/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.2059e-04\n",
            "Epoch 85/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.1908e-04\n",
            "Epoch 86/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1859e-04\n",
            "Epoch 87/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.1911e-04\n",
            "Epoch 88/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1743e-04\n",
            "Epoch 89/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.1823e-04\n",
            "Epoch 90/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1762e-04\n",
            "Epoch 91/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.1626e-04\n",
            "Epoch 92/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1635e-04\n",
            "Epoch 93/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.1703e-04\n",
            "Epoch 94/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1635e-04\n",
            "Epoch 95/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1655e-04\n",
            "Epoch 96/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1429e-04\n",
            "Epoch 97/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1529e-04\n",
            "Epoch 98/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.1522e-04\n",
            "Epoch 99/100\n",
            "3014/3014 [==============================] - 18s 6ms/step - loss: 4.1343e-04\n",
            "Epoch 100/100\n",
            "3014/3014 [==============================] - 19s 6ms/step - loss: 4.1431e-04\n",
            "1/1 [==============================] - 1s 641ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_sequence = scaled_data[-n_steps:]\n",
        "last_sequence = last_sequence.reshape((1, n_steps, 1))\n",
        "predicted_temperature = model.predict(last_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eL0AVDS0T1t",
        "outputId": "4106a565-48d2-4d0e-e441-9a0fdb63d84d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(last_sequence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLTiBChV0WIn",
        "outputId": "190d4e49-b82d-437b-f4dc-9573fe3f0537"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the last time step of the data\n",
        "last_sequence = scaled_data[-n_steps:]\n",
        "last_sequence = last_sequence.reshape((1, n_steps, 1))\n",
        "predicted_temperature = model.predict(last_sequence)\n",
        "\n",
        "# Print predicted_temperature\n",
        "print(\"Predicted Temperature Array:\", predicted_temperature)\n",
        "\n",
        "# Convert the prediction array to a scalar\n",
        "predicted_temperature_scalar = np.squeeze(predicted_temperature)\n",
        "\n",
        "# Inverse transform the predicted temperature scalar\n",
        "predicted_temperature_scalar = scaler.inverse_transform([[predicted_temperature_scalar]])\n",
        "\n",
        "# Compute evaluation metrics\n",
        "y_true = temperature_data[-1]\n",
        "y_pred = predicted_temperature_scalar[-1]\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "print(\"Sample Prediction Details:\")\n",
        "print(\"True Temperature (C):\", y_true)\n",
        "print(\"Predicted Temperature (C):\", y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGFlMmHvrWpv",
        "outputId": "10ac6ec9-136c-436a-9a78-f161b318c0c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Predicted Temperature Array: [[0.6613921]]\n",
            "Sample Prediction Details:\n",
            "True Temperature (C): [20.43888889]\n",
            "Predicted Temperature (C): [19.0040419]\n",
            "Mean Absolute Error (MAE): 1.434846988651497\n",
            "Root Mean Squared Error (RMSE): 1.434846988651497\n",
            "Mean Absolute Percentage Error (MAPE): 7.020180971929041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacked Lstm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import math\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Define the modified split_sequence function\n",
        "def split_sequence(sequence, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the sequence\n",
        "        if end_ix > len(sequence)-1:\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"/content/weather-dataset/weatherHistory.csv\")\n",
        "\n",
        "# Select only the 'Temperature (C)' column\n",
        "temperature_data = data['Temperature (C)'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(temperature_data)\n",
        "\n",
        "# Define the number of time steps\n",
        "n_steps = 10\n",
        "\n",
        "# Split the temperature sequence into input/output\n",
        "X, y = split_sequence(scaled_data, n_steps)\n",
        "\n",
        "# Reshape data for LSTM [samples, time steps, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Define the LSTM model with stacked layers\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(n_steps, 1)))\n",
        "model.add(LSTM(units=50, return_sequences=True))  # Stacked LSTM layer\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, batch_size=64)\n",
        "\n",
        "# Predict on the last time step of the data\n",
        "last_sequence = scaled_data[-n_steps:]\n",
        "last_sequence = last_sequence.reshape((1, n_steps, 1))\n",
        "predicted_temperature = model.predict(last_sequence)\n",
        "\n",
        "# Inverse transform the predicted temperature\n",
        "predicted_temperature = scaler.inverse_transform(predicted_temperature)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk5cdbxvrWna",
        "outputId": "1b258d1e-7ee6-4492-e205-f707c22dc83b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1507/1507 [==============================] - 17s 8ms/step - loss: 0.0043\n",
            "Epoch 2/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 6.5328e-04\n",
            "Epoch 3/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.8602e-04\n",
            "Epoch 4/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.6525e-04\n",
            "Epoch 5/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.5472e-04\n",
            "Epoch 6/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.5079e-04\n",
            "Epoch 7/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.4634e-04\n",
            "Epoch 8/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.3389e-04\n",
            "Epoch 9/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.3237e-04\n",
            "Epoch 10/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.2016e-04\n",
            "Epoch 11/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.2085e-04\n",
            "Epoch 12/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.1813e-04\n",
            "Epoch 13/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.0816e-04\n",
            "Epoch 14/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.0437e-04\n",
            "Epoch 15/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 5.0073e-04\n",
            "Epoch 16/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.9630e-04\n",
            "Epoch 17/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.9529e-04\n",
            "Epoch 18/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.8769e-04\n",
            "Epoch 19/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.8291e-04\n",
            "Epoch 20/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.8203e-04\n",
            "Epoch 21/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.7588e-04\n",
            "Epoch 22/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.7367e-04\n",
            "Epoch 23/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.7202e-04\n",
            "Epoch 24/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.7018e-04\n",
            "Epoch 25/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.6216e-04\n",
            "Epoch 26/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.6378e-04\n",
            "Epoch 27/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.5889e-04\n",
            "Epoch 28/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.5397e-04\n",
            "Epoch 29/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.5625e-04\n",
            "Epoch 30/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.5314e-04\n",
            "Epoch 31/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.5314e-04\n",
            "Epoch 32/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.5114e-04\n",
            "Epoch 33/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4934e-04\n",
            "Epoch 34/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4752e-04\n",
            "Epoch 35/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4590e-04\n",
            "Epoch 36/100\n",
            "1507/1507 [==============================] - 15s 10ms/step - loss: 4.4893e-04\n",
            "Epoch 37/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4686e-04\n",
            "Epoch 38/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4504e-04\n",
            "Epoch 39/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4638e-04\n",
            "Epoch 40/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4224e-04\n",
            "Epoch 41/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4327e-04\n",
            "Epoch 42/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.4428e-04\n",
            "Epoch 43/100\n",
            "1507/1507 [==============================] - 16s 11ms/step - loss: 4.4205e-04\n",
            "Epoch 44/100\n",
            "1507/1507 [==============================] - 15s 10ms/step - loss: 4.3980e-04\n",
            "Epoch 45/100\n",
            "1507/1507 [==============================] - 14s 10ms/step - loss: 4.4071e-04\n",
            "Epoch 46/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3890e-04\n",
            "Epoch 47/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3817e-04\n",
            "Epoch 48/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3841e-04\n",
            "Epoch 49/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3791e-04\n",
            "Epoch 50/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3686e-04\n",
            "Epoch 51/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3560e-04\n",
            "Epoch 52/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3482e-04\n",
            "Epoch 53/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3395e-04\n",
            "Epoch 54/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3321e-04\n",
            "Epoch 55/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3137e-04\n",
            "Epoch 56/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3301e-04\n",
            "Epoch 57/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3175e-04\n",
            "Epoch 58/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.3098e-04\n",
            "Epoch 59/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2994e-04\n",
            "Epoch 60/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2976e-04\n",
            "Epoch 61/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2866e-04\n",
            "Epoch 62/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2972e-04\n",
            "Epoch 63/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2748e-04\n",
            "Epoch 64/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2792e-04\n",
            "Epoch 65/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2642e-04\n",
            "Epoch 66/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2623e-04\n",
            "Epoch 67/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2640e-04\n",
            "Epoch 68/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2480e-04\n",
            "Epoch 69/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2352e-04\n",
            "Epoch 70/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2346e-04\n",
            "Epoch 71/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2420e-04\n",
            "Epoch 72/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2498e-04\n",
            "Epoch 73/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2210e-04\n",
            "Epoch 74/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2187e-04\n",
            "Epoch 75/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2243e-04\n",
            "Epoch 76/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2047e-04\n",
            "Epoch 77/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2071e-04\n",
            "Epoch 78/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2209e-04\n",
            "Epoch 79/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2036e-04\n",
            "Epoch 80/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2168e-04\n",
            "Epoch 81/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1932e-04\n",
            "Epoch 82/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2048e-04\n",
            "Epoch 83/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1994e-04\n",
            "Epoch 84/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.2046e-04\n",
            "Epoch 85/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1864e-04\n",
            "Epoch 86/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1980e-04\n",
            "Epoch 87/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1768e-04\n",
            "Epoch 88/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1787e-04\n",
            "Epoch 89/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1697e-04\n",
            "Epoch 90/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1882e-04\n",
            "Epoch 91/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1778e-04\n",
            "Epoch 92/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1622e-04\n",
            "Epoch 93/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1514e-04\n",
            "Epoch 94/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1641e-04\n",
            "Epoch 95/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1536e-04\n",
            "Epoch 96/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1572e-04\n",
            "Epoch 97/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1615e-04\n",
            "Epoch 98/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1474e-04\n",
            "Epoch 99/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1561e-04\n",
            "Epoch 100/100\n",
            "1507/1507 [==============================] - 12s 8ms/step - loss: 4.1486e-04\n",
            "1/1 [==============================] - 1s 882ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the last time step of the data\n",
        "last_sequence = scaled_data[-n_steps:]\n",
        "last_sequence = last_sequence.reshape((1, n_steps, 1))\n",
        "predicted_temperature = model.predict(last_sequence)\n",
        "\n",
        "\n",
        "# Convert the prediction array to a scalar\n",
        "predicted_temperature_scalar = np.squeeze(predicted_temperature)\n",
        "\n",
        "# Inverse transform the predicted temperature scalar\n",
        "predicted_temperature_scalar = scaler.inverse_transform([[predicted_temperature_scalar]])\n",
        "\n",
        "# Compute evaluation metrics\n",
        "y_true = temperature_data[-1]\n",
        "y_pred = predicted_temperature_scalar[-1]\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "print(\"Sample Prediction Details:\")\n",
        "print(\"True Temperature (C):\", y_true)\n",
        "print(\"Predicted Temperature (C):\", y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRwo2D8arWkk",
        "outputId": "968f3375-67b8-40e5-92cb-0750a32de01b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Sample Prediction Details:\n",
            "True Temperature (C): [20.43888889]\n",
            "Predicted Temperature (C): [19.16473]\n",
            "Mean Absolute Error (MAE): 1.2741588883929857\n",
            "Root Mean Squared Error (RMSE): 1.2741588883929857\n",
            "Mean Absolute Percentage Error (MAPE): 6.233992930435917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#univariate Bidirectional LSTM\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import math\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
        "\n",
        "# Define the modified split_sequence function\n",
        "def split_sequence(sequence, n_steps):\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        # find the end of this pattern\n",
        "        end_ix = i + n_steps\n",
        "        # check if we are beyond the sequence\n",
        "        if end_ix > len(sequence)-1:\n",
        "            break\n",
        "        # gather input and output parts of the pattern\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"/content/weather-dataset/weatherHistory.csv\")\n",
        "\n",
        "# Select only the 'Temperature (C)' column\n",
        "temperature_data = data['Temperature (C)'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(temperature_data)\n",
        "\n",
        "# Define the number of time steps\n",
        "n_steps = 10\n",
        "\n",
        "# Split the temperature sequence into input/output\n",
        "X, y = split_sequence(scaled_data, n_steps)\n",
        "\n",
        "# Reshape data for LSTM [samples, time steps, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Define the Bidirectional LSTM model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=50, input_shape=(n_steps, 1))))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, batch_size=64)\n",
        "\n",
        "# Predict on the last time step of the data\n",
        "last_sequence = scaled_data[-n_steps:]\n",
        "last_sequence = last_sequence.reshape((1, n_steps, 1))\n",
        "predicted_temperature = model.predict(last_sequence)\n",
        "\n",
        "# Inverse transform the predicted temperature\n",
        "predicted_temperature = scaler.inverse_transform(predicted_temperature)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s20_ws9c1-2X",
        "outputId": "89560145-109d-4789-9233-aca0673edb94"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1507/1507 [==============================] - 16s 8ms/step - loss: 0.0027\n",
            "Epoch 2/100\n",
            "1507/1507 [==============================] - 17s 11ms/step - loss: 7.1565e-04\n",
            "Epoch 3/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.9763e-04\n",
            "Epoch 4/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.6949e-04\n",
            "Epoch 5/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.5828e-04\n",
            "Epoch 6/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.4620e-04\n",
            "Epoch 7/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.4575e-04\n",
            "Epoch 8/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.3823e-04\n",
            "Epoch 9/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.3366e-04\n",
            "Epoch 10/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.2675e-04\n",
            "Epoch 11/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 5.2539e-04\n",
            "Epoch 12/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 5.1866e-04\n",
            "Epoch 13/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.1426e-04\n",
            "Epoch 14/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.1419e-04\n",
            "Epoch 15/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.1120e-04\n",
            "Epoch 16/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.1236e-04\n",
            "Epoch 17/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.1010e-04\n",
            "Epoch 18/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.0746e-04\n",
            "Epoch 19/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.0652e-04\n",
            "Epoch 20/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.0633e-04\n",
            "Epoch 21/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.0465e-04\n",
            "Epoch 22/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.0396e-04\n",
            "Epoch 23/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.0233e-04\n",
            "Epoch 24/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 5.0341e-04\n",
            "Epoch 25/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 5.0193e-04\n",
            "Epoch 26/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.9995e-04\n",
            "Epoch 27/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.9828e-04\n",
            "Epoch 28/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.9848e-04\n",
            "Epoch 29/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.9736e-04\n",
            "Epoch 30/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.9496e-04\n",
            "Epoch 31/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.9589e-04\n",
            "Epoch 32/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.9324e-04\n",
            "Epoch 33/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.9082e-04\n",
            "Epoch 34/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.8920e-04\n",
            "Epoch 35/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.8797e-04\n",
            "Epoch 36/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.8554e-04\n",
            "Epoch 37/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.8527e-04\n",
            "Epoch 38/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.8365e-04\n",
            "Epoch 39/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.8122e-04\n",
            "Epoch 40/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.7857e-04\n",
            "Epoch 41/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.7881e-04\n",
            "Epoch 42/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.7630e-04\n",
            "Epoch 43/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.7507e-04\n",
            "Epoch 44/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.7514e-04\n",
            "Epoch 45/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.7184e-04\n",
            "Epoch 46/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.7182e-04\n",
            "Epoch 47/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.7287e-04\n",
            "Epoch 48/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.6901e-04\n",
            "Epoch 49/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.6936e-04\n",
            "Epoch 50/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.6669e-04\n",
            "Epoch 51/100\n",
            "1507/1507 [==============================] - 8s 6ms/step - loss: 4.6654e-04\n",
            "Epoch 52/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.6607e-04\n",
            "Epoch 53/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.6367e-04\n",
            "Epoch 54/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.6269e-04\n",
            "Epoch 55/100\n",
            "1507/1507 [==============================] - 10s 7ms/step - loss: 4.6391e-04\n",
            "Epoch 56/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.6243e-04\n",
            "Epoch 57/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.6106e-04\n",
            "Epoch 58/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.6252e-04\n",
            "Epoch 59/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.6042e-04\n",
            "Epoch 60/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5918e-04\n",
            "Epoch 61/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5953e-04\n",
            "Epoch 62/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5850e-04\n",
            "Epoch 63/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5676e-04\n",
            "Epoch 64/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5820e-04\n",
            "Epoch 65/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.5644e-04\n",
            "Epoch 66/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5540e-04\n",
            "Epoch 67/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.5566e-04\n",
            "Epoch 68/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.5491e-04\n",
            "Epoch 69/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5440e-04\n",
            "Epoch 70/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5457e-04\n",
            "Epoch 71/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5414e-04\n",
            "Epoch 72/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5362e-04\n",
            "Epoch 73/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5341e-04\n",
            "Epoch 74/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5237e-04\n",
            "Epoch 75/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5219e-04\n",
            "Epoch 76/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5180e-04\n",
            "Epoch 77/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5143e-04\n",
            "Epoch 78/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5066e-04\n",
            "Epoch 79/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5078e-04\n",
            "Epoch 80/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5007e-04\n",
            "Epoch 81/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.5021e-04\n",
            "Epoch 82/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4995e-04\n",
            "Epoch 83/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4949e-04\n",
            "Epoch 84/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4793e-04\n",
            "Epoch 85/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4921e-04\n",
            "Epoch 86/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4787e-04\n",
            "Epoch 87/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4821e-04\n",
            "Epoch 88/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4704e-04\n",
            "Epoch 89/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4644e-04\n",
            "Epoch 90/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.4755e-04\n",
            "Epoch 91/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.4621e-04\n",
            "Epoch 92/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.4565e-04\n",
            "Epoch 93/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4517e-04\n",
            "Epoch 94/100\n",
            "1507/1507 [==============================] - 10s 6ms/step - loss: 4.4653e-04\n",
            "Epoch 95/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4481e-04\n",
            "Epoch 96/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4495e-04\n",
            "Epoch 97/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4468e-04\n",
            "Epoch 98/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4464e-04\n",
            "Epoch 99/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4414e-04\n",
            "Epoch 100/100\n",
            "1507/1507 [==============================] - 9s 6ms/step - loss: 4.4260e-04\n",
            "1/1 [==============================] - 1s 635ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the last time step of the data\n",
        "last_sequence = scaled_data[-n_steps:]\n",
        "last_sequence = last_sequence.reshape((1, n_steps, 1))\n",
        "predicted_temperature = model.predict(last_sequence)\n",
        "\n",
        "\n",
        "# Convert the prediction array to a scalar\n",
        "predicted_temperature_scalar = np.squeeze(predicted_temperature)\n",
        "\n",
        "# Inverse transform the predicted temperature scalar\n",
        "predicted_temperature_scalar = scaler.inverse_transform([[predicted_temperature_scalar]])\n",
        "\n",
        "# Compute evaluation metrics\n",
        "y_true = temperature_data[-1]\n",
        "y_pred = predicted_temperature_scalar[-1]\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "print(\"Sample Prediction Details:\")\n",
        "print(\"True Temperature (C):\", y_true)\n",
        "print(\"Predicted Temperature (C):\", y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH99VGtY1-z3",
        "outputId": "5de0cd1c-9b81-42fc-a28f-a64caa07fd1b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "Sample Prediction Details:\n",
            "True Temperature (C): [20.43888889]\n",
            "Predicted Temperature (C): [18.95640649]\n",
            "Mean Absolute Error (MAE): 1.4824823972251764\n",
            "Root Mean Squared Error (RMSE): 1.4824823972251764\n",
            "Mean Absolute Percentage Error (MAPE): 7.253243585227826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COdZXvCH4FxB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}